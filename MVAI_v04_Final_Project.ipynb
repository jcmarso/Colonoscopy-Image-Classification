{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svR0tmQwNNN5"
      },
      "source": [
        "##Zip and upload utils from https://github.com/SHI-Labs/Compact-Transformers/tree/main/src\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd9i-pED8GWq"
      },
      "outputs": [],
      "source": [
        "!unzip utils\n",
        "!pip install timm\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "from utils.transformers import TransformerClassifier\n",
        "from utils.tokenizer import Tokenizer\n",
        "\n",
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.RandomPerspective(distortion_scale=0.05, p=0.5),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/drive/MyDrive/Colonoscopy Images 3' # Make sure you update this path to your own personal path\n",
        "full_dataset = ImageFolder(dataset_path, transform=train_transform)\n",
        "\n",
        "# Split the dataset\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Define the CCT model\n",
        "class CCT(nn.Module):\n",
        "    def __init__(self, img_size=256, embedding_dim=768, n_input_channels=3, n_conv_layers=1,\n",
        "                 kernel_size=7, stride=2, padding=3, pooling_kernel_size=3, pooling_stride=2,\n",
        "                 pooling_padding=1, dropout=0., attention_dropout=0.1, stochastic_depth=0.1,\n",
        "                 num_layers=7, num_heads=6, mlp_ratio=4.0, num_classes=2,  # num_classes set to 2\n",
        "                 positional_embedding='learnable', *args, **kwargs):\n",
        "        super(CCT, self).__init__()\n",
        "\n",
        "        self.tokenizer = Tokenizer(n_input_channels=n_input_channels,\n",
        "                                   n_output_channels=embedding_dim,\n",
        "                                   kernel_size=kernel_size,\n",
        "                                   stride=stride,\n",
        "                                   padding=padding,\n",
        "                                   pooling_kernel_size=pooling_kernel_size,\n",
        "                                   pooling_stride=pooling_stride,\n",
        "                                   pooling_padding=pooling_padding,\n",
        "                                   max_pool=True,\n",
        "                                   activation=nn.ReLU,\n",
        "                                   n_conv_layers=n_conv_layers,\n",
        "                                   conv_bias=False)\n",
        "\n",
        "        self.classifier = TransformerClassifier(\n",
        "            sequence_length=self.tokenizer.sequence_length(n_channels=n_input_channels,\n",
        "                                                           height=img_size,\n",
        "                                                           width=img_size),\n",
        "            embedding_dim=embedding_dim,\n",
        "            seq_pool=True,\n",
        "            dropout=dropout,\n",
        "            attention_dropout=attention_dropout,\n",
        "            stochastic_depth=stochastic_depth,\n",
        "            num_layers=num_layers,\n",
        "            num_heads=num_heads,\n",
        "            mlp_ratio=mlp_ratio,\n",
        "            num_classes=num_classes,\n",
        "            positional_embedding=positional_embedding\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tokenizer(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "def cct_14_for_256x256(pretrained=False, progress=False, img_size=256, positional_embedding='learnable', num_classes=2, *args, **kwargs):\n",
        "    # Adjust num_layers, num_heads, and embedding_dim as appropriate for your task and dataset\n",
        "    # These parameters may need to be tuned based on the performance and resource constraints for 256x256 images\n",
        "    return CCT(num_layers=7, num_heads=4, mlp_ratio=2, embedding_dim=128, kernel_size=3, stride=2, padding=1, img_size=img_size, positional_embedding=positional_embedding, num_classes=num_classes, *args, **kwargs)\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = CCT(num_layers=7, num_heads=4, mlp_ratio=2, embedding_dim=128, kernel_size=3, stride=2, padding=1, img_size=256, positional_embedding='learnable', num_classes=2)\n",
        "\n",
        "# Set device for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Add a learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_val_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "early_stopping_limit = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_targets.extend(labels.tolist())\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    accuracy = 100 * accuracy_score(all_targets, all_predictions)\n",
        "    precision = precision_score(all_targets, all_predictions)\n",
        "    recall = recall_score(all_targets, all_predictions)\n",
        "    f1 = f1_score(all_targets, all_predictions)\n",
        "    confusion = confusion_matrix(all_targets, all_predictions)\n",
        "\n",
        "    # Print statistics\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}')\n",
        "    print(f'Confusion Matrix:\\n{confusion}')\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= early_stopping_limit:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "id": "uzSc9HIE5C9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}